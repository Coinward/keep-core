# Keep Master Test Plan
A keep is an off-chain container for private data. Keeps help contracts harness
the full power of the public blockchain â€” enabling deep interactivity with
private data.

## Document Usage Guide

##### Introduction
The Keep system is a distributed application consisting of two types of
components:
1. The Keep client written in Go
2. The Keep contracts written in Solidity

This test plan includes designs and instructions on how to test these
components individually and during interactions with each other.
Everything depends on successful communications between the Keep clients their
interactions with the Keep contracts via an Ethereum transaction gateway.
We expect to spend much time testing the system under load and under severely
stressful network conditions.

We are testing a fully distributed system and part of our job is to create a
friendly testing environment that is easy to learn and enables every developer
to track down and reproduce bugs with confidence.

Most of the testing will be done in an automated fashion using a dedicated
cloud based test environment. Every developer will have access to this test
environment.

We will make an effort to enable local testing for most components but due to
the complexity of a distributed application it might not be possible to reproduce
all test scenarios locally on a developer machine.

##### Responsibilities
The initial test plan and corresponding tooling will be developed by
Markus Fix and Sloan Thompson in an effort to bootstrap our testing
environment.

##### Roles
As of this time there is no dedicated QA role. Developers will keep adding
regression tests as needed to cover the test scenarios listed in this document.

##### Philosophy
Automated testing is an integral part of continuous delivery. Each time we
merge to master the build system kicks of a build. After a successful build
the artifacts are deployed into the test environment and we run the regression
tests.

Security is a very important concern of the Keep network. One of the
aims of this test plan is to make reasoning about potential exploits easier.

##### Assumptions
All testing will assume a Linux environment with the Keep client
running inside a Docker container that is deployed via Kubernetes.

##### Staffing and training needs
As we get closer to a mainnet release we expect that maintaining and
expanding this testplan will become a job for a full time QA
person. 

##### Deliverables
1. Automated deploy via build server to a cloud test environment.
2. Automated execution of regression tests against a network of Keep
clients.
3. Collection of statistics on test failures.
4. Instructions on how to interactively chase down a bug and turn the
result into a valid regression test.
5. Instructions for third parties on how to setup their own test
environment to run regression tests against proposed code changes
or PRs.

##### Environmental needs
All tests will have to run in a cloud based (GCS) environment. Some
tests will interact with the GCS environment from a local host to
simplify debugging of Keep client features in a tight development
loop.

##### Suspension criteria and resumption requirements
Tests will be run automatically on each merge to master and build.


##### Item pass/fail criteria
All tests must pass before a release can be cut.

##### Approach
1. Unit tests for individual components and in particular all network
and cryptographic components.
2. Network interaction scenarios with known outcomes (group formation)
3. Running 2.) while fuzzing the network
4. Running 2.) while overloading the network
5. Running 2.) while some Keep clients try to cheat

##### Test items
1. Keep client
2. Keep contracts

##### Features to be tested
1. Basic network connectivity between Keep clients
2. Basic network connectivity between Keep clients and a transaction
gateway.
3. Group formation of a set of Keep clients
4. Random Beacon bootstrap
5. Keep contract upgrade from scratch
6. Keep contract upgrade while system has history and is running

##### Features not to be tested
List the features / requirements that
will not be tested and are outside of the scope of this test plan.

tbd.

##### Resources
Project setup and links. Oracles. External tools, test
accounts, mock data, knowledge bases. etc.

tbd.

##### Schedule
Provide a realistic estimate to the time
required. Think about sections, tasks, subsections, regression testing
and publish intervals. This should map to an existing project plan.

tbd.

##### Risks and contingencies
Developing the continuous delivery tooling to automatically build,
deploy and test both Keep client and Keep contracts might take a while
due to running inside a Kubernetes controlled GCS
environment.

Dynamically changing configurations for Keep clients between test runs
and automated contract upgrades are both difficult to achieve.

##### Approvals & Completions
The Keep tech lead will sign off on each iteration of this test plan
before it goes into operation.

##### General Test Coverage
- Unit tests are documented in the source code
- Regression tests are documented here and in the scripts necessary to
  execute them.
- Network fuzzing is documented here and in more detail in the scripts
necessary to execute them.

##### Document Maintenance
All artifacts needed for testing are maintained along the source code
in the GitHub repository. If larger data sets are needed to be stored
they will be kept at a GCS accessible file store.

## Testing **Plans, Areas, Methods, Features and Checklists**
Testing the app from 10K ft. to 0.01 mm away. This is where we start
to get our hands dirty.

### Smoke Tests
Identify and attempt to *automate* the core functions
that needs to pass in order for a build to be ready for
testing. Perhaps passing unit tests first. Perhaps just confirming the
build can open and close. Perhaps any automated tests you have laying
around. Figure this out and attach it to the build process.

### Unit Testing
At build time the build server runs all attached unit tests. Builds
fail if a single unit test fails. No artifacts are deployed to the
test environment in this case.
##### TBD.
1. List of unit tests for networking
2. List of unit tests for cryptography

### Automated Testing
List all regression tests we are running

### Basic CRUD Testing
Here we document the deploy process for the test environment that
creates accounts for Keep clients on the transaction node, funds those
accounts and stakes for them.

Once this is done we run the deployed Keep clients through a number of
basic scenarios to test them.

### Hardware Testing
We need to define the minimum requirements for the deployed Docker
containers including RAM, storage and CPU.
We need to do a test run using these minimum requirements.

tbd.

### Feature Testing
1. How do we test Group Formation?
2. How do we test the Random Beacon?


### Configuration Testing
1. Test configuration for boot nodes
2. Test configuration for normal nodes

### Security Testing
We want to make sure Keep clients can operate under a number of
adverse conditions:
1. Request fuzzing
2. Network fuzzing
3. Cheating Keep clients
4. ...?


### Upgrade & Installation Testing
Test version upgrades when we prepare a major release. This *must*
include testing contract upgrades and their interactions with older
Keep clients.

### Analytics Testing
1. Test analytics can be activated and report accurate results.
2. Test analytics can be switched off

### First Run Experience Testing
Test the inital user experience from zero to running Keep client.


### Modes and States Testing
Test how a new release of the Keep client and new contracts will
interact with immutable on-chain data. There is no roll back option
for on Keep contracts. We need to make sure the contract upgrade
procedure has been thoroughly tested.

### Network Testing
1. Overload the network using a tool like Pumba
2. Drop packets using Pumba during group formation and other phases
3. Inject malicious packets
4. ...


### Stress & Performance Testing
1. Run our test network with 10, 100, 1000 Keep clients
2. Test all features while Keep clients are connected to different
tx-nodes


### Chaos Monkey Testing
1. Randomly kill Keep clients while testing features
2. Randomly interrupt the connection to the tx-node while testing features

### Scenario Testing
Develop use cases and stories. Extract examples
from the team, from the support queue and our potential
customers. Your stakeholders from all points of entry. As a _$USER_ I
need to _$ACTION_ so that I can _$RESULT_.

tbd.

### Regression Testing
Performance vs last public release. Versus last
beta, alpha, build, update, etc.

tbd.

