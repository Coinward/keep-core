= Staking models

To develop a suitable staking model for the network,
it is necessary to choose between two different models
for handling stakes: _leveraged_ or _fully backed_.

== Fully backed staking
Staked tokens are divided to
_free stakes_ that can be used as collateral for new operations,
and _locked stakes_ that are already backing some existing operation.
When a (virtual) staker joins a new operation
requiring some amount of tokens as collateral,
the staker is required to _lock up_ some of their _free stake_.
+
This _locked stake_ is held as collateral
to ensure any misbehavior in the operation can be properly penalized,
and cannot be used for any other operation.
When the operation finishes,
all stake locked for that particular operation is released.
+
This ensures that all operations are always _fully backed_ by actual stake,
and operations never interfere with each other's stakes.
However, the network throughput is limited
because there is only so much stake available for collateral,
especially for operations requiring high stakes.

== Leveraged staking
When operations require tokens as collateral,
stakers who join the operation are required to hold sufficient stake
without considering other operations.
A staker is able to join more operations
than they could pay the maximum penalty for,
thus becoming _leveraged_.
+
If a _leveraged_ staker gets penalised on some of their operations,
their token balance may fall below
the amount they would be slashed for some subsequent misbehavior.
A staker whose penalty exceeds their remaining stake
_defaults_ on the operation.
The possibility of a default
can significantly reduce the incentives for correct behavior.
+
On the upside,
leveraged staking is simpler and cheaper to implement,
it has no limits on the number of concurrent operations,
and the _marginal deterrent_ to misbehavior can be higher.

== Demand and network throughput
Let a staker's _used stake_ be the sum of the stakes required
for each operation they participate in.
In fully backed staking _used stake = locked stake_.
With leveraged staking,
_used stake_ equals the sum of all penalties the staker could incur
from misbehaving on each operation they participate in.

A staker's _usage ratio (UR)_ equals ther _used stake / total stake_.
In fully backed staking
each staker by definition has a usage ratio between 0 and 1.
Let the system's _average usage ratio (AUR)_ be
the _total used stake / total tokens staked_ across all stakers.
This is also between 0 and 1.

=== Scaling with fully backed staking
Because _used stake = stake per operation * concurrent operations_,
the limit of _UR = 1_ limits the number of concurrent operations
to _total tokens staked / stake per operation_.
Correspondingly,
the only way to increase the limit on concurrent operations
is to reduce the _stake per operation_ as demand increases.

==== Adjustment by hard fork
The simplest method would be to perform hard forks
to update stake requirements whenever usage gets too high.
This is unlikely to be viable
for a successful system aiming at significant growth.

==== Decreasing stake requirements
Another relatively simple method would be to reduce stakes and penalties
dynamically as usage increases.
Any new operations after the adjustment would use the new stake quantities,
while existing operations stay on the old stakes until released.

Because the update applies incrementally,
it would be necessary to maintain a sufficient margin
to avoid running out of free stake.
For example, stakes could be halved globally whenever the UR exceeds 0.5.

This has the downside that pre-update and post-update stakes are inequal.
Someone joining an operation just before the update
would have locked up twice the tokens for the same reward
as someone joining a similar operation shortly after.

Additionally, the protocol may not be able to cope with rapid growth
if demand rises faster than old operations end and release more tokens.
Determining the update threshold in periods of rapid growth
would require complex formulae to avoid running out of free tokens.

==== Separate stake units
If locked stakes are denominated in _stake units_
instead of absolute token amounts,
scaling the system becomes relatively simple.

The exchange rate of tokens to stake units
would be centrally managed based on the usage ratio,
and any actions involving stake would use the latest exchange rate.
Work contracts would define their stake requirements in stake units,
and locked stakes would be denominated in stake units as well.

If Alice, with 3 stake,
joins an operation requiring 2 stake units
when the exchange rate is 1,
the staking contract would record 2 stake units locked up.
At this time Alice's locked stakes would be worth 2/3 tokens,
and thus she would not be eligible
to join another operation requiring 2 stake units.

If the exchange rate rises to 1.4 stake units per token,
Alice's 3 staked tokens would equal 4.2 stake units.
Now Alice would be able to join another operation,
bringing her locked stake units to 4, worth 2.86 tokens.

When Alice finishes one operation honorably,
the corresponding 2 stake units are unlocked.
If Alice gets penalized,
the penalty is denominated in stake units
and her tokens are seized according to the exchange rate.
If the exchange rate is 1.7 at the time of a penalty of 2 units,
Alice's stake would be slashed by 1.18 tokens.

The exchange rate could be updated in a very fine-grained manner,
and stakes would be freed up immediately to match growing demand. 

== Leverage, overleverage and attacks
Call the ratio _used stake / stake_ the _leverage ratio_.
This is the same formula as the _usage ratio_ of fully backed staking,
but is not constrained to be below 1.

If Alice has 50 stake and is participating in 7 operations,
each of which could cause a punishment of 5 stake for misbehavior,
Alice's _used stake_ is 35 and her _leverage ratio_ is 0.7.
If Bob participates in 12 operations his _used stake_ would be 60,
leading to a _leverage ratio_ of 1.2.
A staker can be called _leveraged_ when their _leverage ratio_ exceeds 1;
with _leverage ratio =< 1_ the staker is _unleveraged_.

If there is 10,000 stake in the system overall,
and 1,000 stakers participating on average in 2.8 operations,
with 14 tokens at stake,
the _average leverage ratio_ is 1.4.
With leveraged stakes, _average leverage ratio_ equals the _demand ratio_.

If Alice has a _leverage ratio_ exceeding the _average leverage ratio_,
she may be called _overleveraged_ relative to other stakers.
Let _overleverage ratio_ equal
_leverage ratio / max(1, average leverage ratio)_.
If Alice's LR is 3.0 and the ALR is 2.0,
Alice's _overleverage ratio_ would be 1.5.
If Bob's LR is 1.8 he would be _underleveraged_ at OR = 0.9.

=== Overleverage attacks
When a staker misbehaves,
the standard recourse is to punish them by taking away staked tokens.
If Mallory has a high leverage ratio,
their operations aren't all backed by actual stake.
Thus it becomes possible for Mallory to misbehave in multiple operations
while suffering far less than the face value of the penalty.

We have three relevant concepts:

marginal deterrent::
How much Mallory would lose by misbehaving _once_,
at the most favorable opportunity available

total deterrent::
How much Mallory would lose by misbehaving
on some or all operations they are participating in

per-operation deterrent::
_total deterrent / affected operations_;
how much Mallory would lose _per operation_
by misbehaving on multiple operations

Overleverage attacks exploit the difference
between marginal deterrent when misbehaving on one operation
and per-operation deterrent when misbehaving on many.
If Mallory has multiple operations backed by the minimum stake,
and it gets slashed away entirely from one misbehavior,
misbehaving on the remaining operations is effectively free.

In this basic scenario
Mallory's _marginal deterrent_ equals their _total deterrent_,
and the effective _per-operation deterrent_ equals the minimum stake
divided by Mallory's leverage ratio.

==== Demand ratio and overleverage
When analyzed in a vacuum,
it appears as if any degree of leverage would render the network vulnerable.
However, when comparing atomic and leveraged staking,
it is necessary to consider the demand ratio as well.

When the demand ratio (DR) is below 1,
all operations use the same stake regardless of the staking model.
With the average leverage ratio (ALR) equaling the demand ratio,
all stakers whose stakes are leveraged are by definition overleveraged.

When the DR exceeds 1,
atomic staking necessitates reducing the minimum stake. 
This changes the balance between atomic and leveraged staking,
as atomic staking can only sustain a maximum penalty of
_initial minimum stake / demand ratio_.
Leveraged stake has no such constraint
and the minimum stake and maximum penalty can stay constant.

The result of this asymmetry is that an absolutely leveraged staker
whose leverage ratio equals the DR = ALR
will still have the same _total deterrent_ over all their operations
as they would under atomic staking,
while having a significantly greater _marginal deterrent_.
This discrepancy is arguably desirable
if opportunities to profitably misbehave are uncommon.

A different picture emerges when considering a staker
who is _overleveraged_ compared to the average.
In this case the marginal deterrent remains high,
but the effective _per-operation deterrent_ is divided by the OR.
Under atomic staking it is not possible to become overleveraged
and per-operation deterrent remains constant.

.Deterrent amounts
|===
|Type |Value under atomic staking |Value under leveraged staking

|Marginal deterrent
|minimum stake
|minimum stake / DR

|Total deterrent
|staked tokens
|staked tokens

|Per-operation deterrent
|minimum stake / (DR * OR)
|minimum stake / DR
|===

Thus the name _overleverage attack_.

==== Blitzpantsing reduction
The law of large numbers significantly reduces the likelihood
of a staker having a large overleverage ratio
as their total stake increases.
This can be entirely circumvented with blitzpantsing.
Because operations are joined on the granularity of virtual stakers,
a large staker is practically guaranteed
to have some of their virtual stakers _overleveraged_
while others are _underleveraged_.
Dividing these virtual stakers to separate identities
removes the smoothing effect of the law of large numbers
and lets the adversary pick the most favorable identities
for the overleverage attack.

Mallory has _m~total~_ virtual stakers.
_m~avg~_ of these stakers have the same leverage ratio as the average;
_m~over~_ are overleveraged,
and _m~under~_ are underleveraged compared to the average.

With an _ALR = LR~mallory~ = 1_, we get the following numbers:

m~under~ = P(0, 1) * m~total~ = 0.37 * m~total~

m~avg~ = P(1, 1) * m~total~ = 0.37 * m~total~

m~over~ = P~over~(1, 1) * m~total~ = 0.26 * m~total~

The average leverage ratio of the overleveraged virtual stakers
is _0.63 / 0.26 = 2.42_.
If Mallory only leaves out the virtual stakers whose stake sits unused,
the effective overleverage ratio of the other virtual stakers
is _1 / 0.63 = 1.59_.

This means that any large staker,
even if they are _underleveraged_ compared to the average,
is probably able to perform an overleverage attack with blitzpantsing.
Furthermore, any overleverage attack can be strengthened by blitzpantsing
and leaving out the stakes of those virtual stakers
who haven't been selected for any operations.
With a monolithic stake those stakes would be diluting the overleverage
without contributing any misbehavior opportunities.
In the case where each virtual staker
participates in exactly the same number of operations,
the attack will not be weakened.

The blitzpantsing reduction makes overleverage attacks
significantly simpler to analyze.
Instead of calculating complicated probability distributions for large stakers,
it is sufficient to calculate the distribution
of overleverage ratios for minimum stakers,
given some average leverage ratio.
The attack produced by picking and choosing
blitzpantsed staker identities with favorable overleverage ratios
will always be as strong or stronger than
what would be possible with monolithic staking.

==== Overleverage attack mitigation
As the ALR increases, the viability of overleverage attacks decreases.
An OR of 2 is much easier to achieve with an ALR of 1,
where a minimum staker needs to join 2 operations,
than with an ALR of 10 where 20 operations would be required.
In the latter case only 0.35% of minimum stakers would have an OR of 2 or more,
compared to the 26% of the first scenario.

|===
|ALR |Minimum LR for OL >= 2 |Probability (poisson)

|1 |2 |0.26
|2 |4 |0.14
|3 |6 |0.084
|4 |8 |0.051
|5 |10 |0.032
|10 |20 |0.0035
|===

A lower ALR also provides protection from overleverage attacks,
as the fraction of used stake held by overleveraged virtual stakers decreases:

|===
|ALR |P(1, ALR) |P~over~(1, ALR) |Overleveraged fraction |Average overleverage

|0.5 |0.30 |0.090 |0.4 |2.22
|0.4 |0.27 |0.062 |0.33 |2.10
|0.25 |0.19 |0.027 |0.24 |2.22
|0.1 |0.090 |0.0047 |0.1 |2.12
|===

While maintaining a low ALR is not viable for a successful system,
it is possible to get the benefits of a high ALR with a lower DR
by requiring a higher minimum stake.
If the minimum stake is higher than the maximum penalty,
fewer virtual stakers will become overleveraged
and those that do will have a lower OR.








== [old notes]

== Atomic staking

With atomic staking, each operation is backed by hard tokens.
When Alice joins an operation requiring 5 tokens in stake,
she will need to lock up those 5 tokens until that operation is finished.

Atomicity guarantees that all stakers
will always have the specified amount of tokens at stake for each operation.
This has the attractive property
of preventing situations where somebody could misbehave "for free"
by having no stake to be slashed.

However, a serious downside of atomicity is
that the throughput of the network has a hard limit at
_concurrent operations =< total tokens staked / stake per operation_.
To deal with this, the _stake per operation_ needs to be reduced
as network demand increases.
This creates a symmetrical constraint in
_stake per operation =< total tokens staked / concurrent operations_.

Let Alice's _used stake_ be the sum of the stakes required
for each operation Alice is participating in.
The _usage ratio_ is the ratio of _used stake / stake_.
Atomic staking by definition has a usage ratio between 0 and 1.
Let _average usage ratio = total used stake / total tokens staked_.

Let the _demand ratio_ be
_concurrent operations * initial minimum stake / total tokens staked_.
When the _demand ratio_ exceeds 1,
the minimum stake must be reduced to allow further network operations.
If _demand ratio = 4_,
and _current minimum stake = initial minimum stake / 8_,
the _average usage ratio_ would be 0.5.

== Leveraged stakes

Without atomic staking, a staker can end up _leveraged_:
i.e. Alice may be participating in so many operations
that her total stakes would be insufficient
to cover the maximum penalty for all of them.
This can theoretically result in a situation
where Alice's stake is slashed in its entirety
by a small number of misbehaviors,
leaving no effective deterrent to further misbehavior.

=== Leverage ratio




== Improving atomic staking

Atomic staking has two main weaknesses:
complexity of implementation and increased state in the system,
and the throughput constraints.
While the first is unavoidable,
the throughput of atomic staking must be able to scale
for the system to be successful.
This necessitates lowering the stake requirements as demand increases.

== Analysis

When comparing atomic and leveraged staking,
a crucial consideration is whether one or the other
provides a more effective deterrent to misbehavior
under different scenarios.

We have three categories of scenarios to consider:

1. when the _demand ratio_ is below 1;
in _atomic staking_ most stakers' _usage ratio_ is below 1,
while in _leveraged staking_ most stakers' _leverage ratio < 1_

2. when the _demand ratio_ is exactly 1;
in _atomic staking_ all stakers are at _usage ratio = 1_,
while in _leveraged staking_ the _average leverage ratio = 1_
but some stakers remain _underleveraged_ and others can be _overleveraged_

3.  when the _demand ratio_ exceeds 1;
in _atomic staking_ the minimum stake has been reduced to permit throughput,
while in _leveraged staking_ most stakers are leveraged,
with randomly varying overleverage ratios

Where numbers are required,
we can use the sample distribution based on empirical power law observations.
Simplify the calculations by dividing all token amounts
by the initial minimum stake of 10,000;
thus the initial minimum stake _MinStake = 1_,
and the total token supply is _100,000_.

Assume a group size _N_ of 100,
that all stakers are active at all times,
and all stakes are optimally staked
(everybody stakes an exact integer multiple of the minimum).

Let _P(n, s)_ be the probability of a staker with _s_ staked tokens
participating in _n_ operations.

_P~over~(n, s) = sum[i = n+1..inf]( P(i, s) )_;
the probability of more than _n_ operations with _s_ stake

_P~under~(n, s) = sum[j = 0..n-1]( P(j, s) )_
the probability of less than _n_ operations with _s_ stake

Let _P~selected~(k, s)_ be the probability of a staker with _s_ tokens
being selected for a group _k_ times.

Let _Hgeo(k, N, K, n)_ be the hypergeometric probability function
of drawing _k_ specimens out of _n_ samples,
when the population is _N_ containing _K_ specimens.

Let _Bin(k, n, P)_ be the binomial probability function
of getting _k_ independent successes on _n_ tries,
when the probability of success is _P = K / N_.

=== Scenario 1: DR < 1

=== Scenario 2: DR = 1

For simplicity, assume atomic staking is at full capacity
as the minimum stake has not been reduced.

With atomic staking, the math remains simple:

* marginal deterrent = minimum stake = 10,000 KEEP
* total deterrent = minimum stake * active operations
* per-operation deterrent = minimum stake

With leveraged staking, the situation becomes more complex:

A minimum staker has _P(1, 1)_ of being exactly even;
a _P(0, 1)_ of not participating in any operation;
_P~over~(1, 1)_ of being (over)leveraged.

With actual numbers:

There are 100,000 tokens staked.
With _N = 100_ we get 1,000 groups active at any time.

_P~selected~(k, s) = Hgeo(k, 100000, s, 100)_

_P(0, s) = Bin(0, 1000, ( 1 - P~selected~(0, s) ))_

_P(0, 1) = Bin(0, 1000, P~selected~(1, 1))_

_P(0, 1) = Bin(0, 1000, Hgeo(1, 100000, 1, 100))_
or 0.368

_P(1, 1) = 0.368_
_P(2, 1) = 0.184_
_P(3, 1) = 0.061_
_P(4, 1) = 0.015_
_P(5, 1) = 0.003_
_P~over~(5, 1) = 0.0005_

_P(10, 10) = 0.126_
_P~under~(10, 10) = 0.457_
_P~over~(10, 10) = 0.417_
_P~over~(20, 10) = 0.0015_

P(3, 2) = 0.180
P(4, 2) = 0.090
P(5, 2) = 0.036
P(6, 2) = 0.012
P(7, 2) = 0.0034
P(8, 2) = 0.00086
P(9, 2) = 0.00019
P~over~(9, 2) = 0.00005

=== Scenario 3: DR > 1
